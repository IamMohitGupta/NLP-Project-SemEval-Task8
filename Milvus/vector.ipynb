{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting clapnq.jsonl.zip...\n",
      "✓ Extracted!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = \"../corpora/passage_level/clapnq.jsonl.zip\"\n",
    "extract_dir = \"../corpora/passage_level/\"\n",
    "\n",
    "# Extract only if not already extracted\n",
    "target_file = os.path.join(extract_dir, \"clapnq.jsonl\")\n",
    "\n",
    "if not os.path.exists(target_file):\n",
    "    print(\"Extracting clapnq.jsonl.zip...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(extract_dir)\n",
    "    print(\"✓ Extracted!\")\n",
    "else:\n",
    "    print(\"clapnq.jsonl already exists, skipping unzip.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Collection created\n",
      "Loading MiniLM embeddings model...\n",
      "✓ Model loaded\n",
      "Reading passages...\n",
      "✓ Loaded 183408 passages\n",
      "Starting embedding + insertion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 717/717 [13:21<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Finished inserting all passages\n",
      "Building vector index...\n",
      "✓ Index built\n",
      "✓ Collection loaded & ready for search!\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "#############################################\n",
    "# 1. Connect to Milvus\n",
    "#############################################\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    host=\"127.0.0.1\",   # works in your setup\n",
    "    port=\"19530\"\n",
    ")\n",
    "\n",
    "#############################################\n",
    "# 2. Create Collection Schema\n",
    "#############################################\n",
    "collection_name = \"clapnq_passages\"\n",
    "\n",
    "# Drop if exists\n",
    "from pymilvus import utility\n",
    "if utility.has_collection(collection_name):\n",
    "    utility.drop_collection(collection_name)\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.VARCHAR, is_primary=True, max_length=200),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384),  # MiniLM output dimension\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=65535),\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, description=\"ClapNQ passage-level corpus\")\n",
    "collection = Collection(name=collection_name, schema=schema)\n",
    "print(\"✓ Collection created\")\n",
    "\n",
    "#############################################\n",
    "# 3. Load MiniLM Model\n",
    "#############################################\n",
    "print(\"Loading MiniLM embeddings model...\")\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"✓ Model loaded\")\n",
    "\n",
    "#############################################\n",
    "# 4. Load ClapNQ Passages\n",
    "#############################################\n",
    "path = \"/Users/mohit/Desktop/Sem Eval task 8/NLP-Project-SemEval-Task8/corpora/passage_level/clapnq.jsonl\"\n",
    "\n",
    "passage_ids = []\n",
    "passage_texts = []\n",
    "\n",
    "print(\"Reading passages...\")\n",
    "with open(path) as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        passage_ids.append(obj[\"_id\"])\n",
    "        passage_texts.append(obj[\"text\"])\n",
    "\n",
    "print(f\"✓ Loaded {len(passage_ids)} passages\")\n",
    "\n",
    "#############################################\n",
    "# 5. Insert in Batches with Embeddings\n",
    "#############################################\n",
    "BATCH = 256\n",
    "print(\"Starting embedding + insertion...\")\n",
    "\n",
    "for i in tqdm(range(0, len(passage_texts), BATCH)):\n",
    "    batch_ids = passage_ids[i:i+BATCH]\n",
    "    batch_texts = passage_texts[i:i+BATCH]\n",
    "\n",
    "    # Generate embeddings (MiniLM -> 384-dim)\n",
    "    batch_embeddings = model.encode(batch_texts, convert_to_numpy=True).tolist()\n",
    "\n",
    "    # Insert into Milvus\n",
    "    collection.insert([batch_ids, batch_embeddings, batch_texts])\n",
    "\n",
    "print(\"✓ Finished inserting all passages\")\n",
    "\n",
    "#############################################\n",
    "# 6. Create Index\n",
    "#############################################\n",
    "index_params = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"COSINE\",\n",
    "    \"params\": {\"nlist\": 2048}\n",
    "}\n",
    "\n",
    "print(\"Building vector index...\")\n",
    "collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "print(\"✓ Index built\")\n",
    "\n",
    "#############################################\n",
    "# 7. Load Collection for Searching\n",
    "#############################################\n",
    "collection.load()\n",
    "print(\"✓ Collection loaded & ready for search!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 0: [-0.11855029 -0.02213986  0.01778213 -0.02428699 -0.00693649  0.00115193\n",
      " -0.0012625   0.04398824 -0.00718389  0.05651155]... (dim=384)\n",
      "Embedding 1: [-0.02696555 -0.01277182  0.02977032 -0.08650455  0.06651282  0.03194625\n",
      " -0.03068677  0.01504944 -0.00052012 -0.0320821 ]... (dim=384)\n",
      "Embedding 2: [-0.021848    0.07122426  0.00184692 -0.11089488  0.02228159  0.01925579\n",
      " -0.02854635 -0.02844507  0.01250403 -0.02986964]... (dim=384)\n",
      "Embedding 3: [ 0.00701434  0.00355477 -0.01642065 -0.08840613  0.10574561  0.03929438\n",
      "  0.01180612 -0.02926991 -0.04262488  0.03408423]... (dim=384)\n",
      "Embedding 4: [-0.03925532 -0.00158098  0.02350306 -0.01048431  0.04540617  0.03902591\n",
      " -0.04975101  0.0625867  -0.0528319  -0.01387044]... (dim=384)\n",
      "Embedding 5: [ 0.09981296  0.03689335 -0.0677207  -0.06775098  0.08487421  0.00608058\n",
      "  0.02794629 -0.04413663  0.03554465  0.00873239]... (dim=384)\n",
      "Embedding 6: [-0.06892251 -0.0256021   0.00053463 -0.0173679  -0.01588602  0.01997466\n",
      "  0.03531457  0.04136641 -0.05784315  0.03201466]... (dim=384)\n",
      "Embedding 7: [-0.00037037  0.03268924 -0.02159727  0.03846634  0.09203841  0.03542484\n",
      "  0.0198022   0.07921433 -0.00918095  0.01825479]... (dim=384)\n",
      "Embedding 8: [-0.00757764  0.03249165  0.00057352 -0.00263553  0.06974159  0.02002492\n",
      "  0.03079503  0.10025892  0.02962441 -0.02762082]... (dim=384)\n",
      "Embedding 9: [ 0.03115204  0.04824591 -0.02545237 -0.08894457  0.08326529  0.01471463\n",
      " -0.04178195 -0.02867009 -0.02207232  0.01838059]... (dim=384)\n"
     ]
    }
   ],
   "source": [
    "# Print first 3 embeddings after encoding\n",
    "emb = model.encode(passage_texts[:10])\n",
    "for i, e in enumerate(emb):\n",
    "    print(f\"Embedding {i}: {e[:10]}... (dim={len(e)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837799097_6931-7548-0-617 0.627049446105957\n",
      "French Revolution\n",
      "After the Thermidorian Reaction , an executive council known as the Directory assumed control of the French state in 1795 . They suspended elections , repudiated debt - resulting in financial instability , persecuted the Catholic clergy , and made significant military conquests abroad . Dogged by charges of corruption , the Directory collapsed in a coup led by Napoleon Bonaparte in 1799 . Napoleon , who became the hero of the Revolution through his popular military campaigns , established the Consulate and later the First Empire , setting the stage for a wider array of global conflicts in the Napoleonic Wars .\n",
      "----\n",
      "837799097_88359-88956-0-597 0.6068961024284363\n",
      "French Revolution\n",
      "Although committed to Republicanism , the Directory distrusted democracy . Historians have seldom praised the Directory ; it was a government of self - interest rather than virtue , thus losing any claim on idealism . It never had a strong base of popular support ; when elections were held , most of its candidates were defeated . Its achievements were minor . Brown stresses the turn towards dictatorship and the failure of liberal democracy under the Directory , blaming it on , `` chronic violence , ambivalent forms of justice , and repeated recourse to heavy - handed repression . '' General\n",
      "----\n",
      "807203428_28578-29018-0-440 0.5658490657806396\n",
      "Modern history\n",
      "The Executive Directory was a body of five Directors that held executive power in France following the Convention and preceding the Consulate . The period of this regime ( 2 November 1795 until 10 November 1799 ) , commonly known as the Directory ( or Directoire ) era , constitutes the second to last stage of the French Revolution . Napoleon , before seizing the title of Emperor , was elected as First Consul of the Consulate of France .\n",
      "----\n",
      "837799097_87714-88358-0-640 0.5614560842514038\n",
      "French Revolution\n",
      "The constitutional party in the legislature desired toleration of the nonjuring clergy , the repeal of the laws against the relatives of the émigrés , and some merciful discrimination towards the émigrés themselves . The directors baffled all such endeavours . On the other hand , the socialist conspiracy of Babeuf was easily quelled . Little was done to improve the finances , and the assignats continued to fall in value until each note was worth less than the paper it was printed on ; debtors easily paid off their debts . A series of financial reforms started by the Directory finally took effect after it fell from power . Evaluation\n",
      "----\n",
      "837799097_86639-86939-0-300 0.5396738648414612\n",
      "French Revolution\n",
      "The Directory denounced the arbitrary executions of the Reign of Terror , but itself engaged in large scale illegal repressions , as well as large - scale massacres of civilians in the Vendee uprising . The economy continued in bad condition , with the poor especially hurt by the high cost of food .\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "query = \"What caused the fall of the French Directory?\"\n",
    "\n",
    "embedding = model.encode([query]).tolist()\n",
    "\n",
    "results = collection.search(\n",
    "    data=embedding,\n",
    "    anns_field=\"embedding\",\n",
    "    param={\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 10}},\n",
    "    limit=5,\n",
    "    output_fields=[\"text\"]\n",
    ")\n",
    "\n",
    "for hit in results[0]:\n",
    "    print(hit.id, hit.distance)\n",
    "    print(hit.entity.get(\"text\"))\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpassage_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sentence_transformers/SentenceTransformer.py:1130\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[0;32m-> 1130\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[1;32m   1134\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(passage_texts, convert_to_numpy=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(\"clapnq_embeddings.npy\", embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
